{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ac7dab-34ae-4a55-9980-3b669ea4f9f4",
   "metadata": {},
   "source": [
    "# Predicting Amazon reviews of Android apps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961e9628-be03-4f5b-9834-82a1d4dfcca0",
   "metadata": {},
   "source": [
    "### Version 1.0\n",
    "#### Simon Yang\n",
    "last update: 25th September 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885429e7-fce8-4637-8e87-53bda950cdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58c65198-7f2e-4561-b803-69a8b722de63",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9242173-8aef-4bae-832e-b82462fd38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "# from fuzzysearch import find_near_matches\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import fasttext\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36b083-053f-4ade-86f7-3ae296e39f21",
   "metadata": {},
   "source": [
    "import ntlk data for text clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4d097f6e-c7df-44c5-9663-e46972036b12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yangsim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/yangsim/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/yangsim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/yangsim/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/yangsim/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yangsim/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd086b1f-d7c5-4278-86bd-c72cd4f69f5e",
   "metadata": {},
   "source": [
    "### Download data (optional)\n",
    "For this script to be fully self-contained, the data would be pulled here. \n",
    "For the purpose of this exercise, the data was pulled with wget and uncompressed to './data/'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9c7e08-683a-4c16-b78b-2a3b172fdf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib\n",
    "# todownload = 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Apps_for_Android_5.json.gz'\n",
    "# urllib.urlretrieve(\"todownload\", \"reviews_Apps_for_Android_5.json.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7cb8fb-da11-495f-8ad7-4772307129bf",
   "metadata": {},
   "source": [
    "### Read data (Amazon reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e147cb0-d46a-4dd8-9cd7-dbb08068a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzr = []\n",
    "for line in open('./data/reviews_Apps_for_Android_5.json', 'r'):\n",
    "    amzr.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d103b3ea-e719-4896-aa2b-eb254381a891",
   "metadata": {},
   "source": [
    "### repackage data into pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca9c5c-6a2e-41a7-b967-df7b4cfa5108",
   "metadata": {},
   "source": [
    "##### First we retrieve all possible unique user key to define our table's columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7260fe62-074b-494c-9e14-1d5863cc1fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = set([i for r in amzr for i in r.keys()])\n",
    "# Create dictionarry -- this will be used to create our DataFrame\n",
    "amzr_df = {c:[] for c in columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3cfb98-4db1-4339-abab-d4dcd473870c",
   "metadata": {},
   "source": [
    "##### Let's fill our table with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23a7336f-7324-450a-bb18-973f933b28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in amzr: # loop through data and append to dict\n",
    "    for key in columns:\n",
    "        amzr_df[key].append(row.get(key))\n",
    "amzr_df = pd.DataFrame(amzr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4f73680d-9b0c-40d5-9b5a-31a7a0d783ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1N4O8VOJZTDVB</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1383350400</td>\n",
       "      <td>Loves the song, so he really couldn't wait to ...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>11 2, 2013</td>\n",
       "      <td>Annette Yancey</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Really cute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2HQWU6HUKIEC7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1323043200</td>\n",
       "      <td>Oh, how my little grandson loves this app. He'...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>12 5, 2011</td>\n",
       "      <td>Audiobook lover \"Kathy\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2-year-old loves it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1SXASF6GYG96I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1337558400</td>\n",
       "      <td>I found this at a perfect time since my daught...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>05 21, 2012</td>\n",
       "      <td>Barbara Gibbs</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Fun game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2B54P9ZDYH167</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1354752000</td>\n",
       "      <td>My 1 year old goes back to this game over and ...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>12 6, 2012</td>\n",
       "      <td>Brooke Greenstreet \"Babylove\"</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>We love our Monkeys!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFOFZDTX5UC6D</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1391212800</td>\n",
       "      <td>There are three different versions of the song...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>02 1, 2014</td>\n",
       "      <td>C. Galindo</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is my granddaughters favorite app on my K...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID  overall  unixReviewTime  \\\n",
       "0  A1N4O8VOJZTDVB      3.0      1383350400   \n",
       "1  A2HQWU6HUKIEC7      5.0      1323043200   \n",
       "2  A1SXASF6GYG96I      5.0      1337558400   \n",
       "3  A2B54P9ZDYH167      5.0      1354752000   \n",
       "4   AFOFZDTX5UC6D      5.0      1391212800   \n",
       "\n",
       "                                          reviewText        asin   reviewTime  \\\n",
       "0  Loves the song, so he really couldn't wait to ...  B004A9SDD8   11 2, 2013   \n",
       "1  Oh, how my little grandson loves this app. He'...  B004A9SDD8   12 5, 2011   \n",
       "2  I found this at a perfect time since my daught...  B004A9SDD8  05 21, 2012   \n",
       "3  My 1 year old goes back to this game over and ...  B004A9SDD8   12 6, 2012   \n",
       "4  There are three different versions of the song...  B004A9SDD8   02 1, 2014   \n",
       "\n",
       "                    reviewerName helpful  \\\n",
       "0                 Annette Yancey  [1, 1]   \n",
       "1        Audiobook lover \"Kathy\"  [0, 0]   \n",
       "2                  Barbara Gibbs  [0, 0]   \n",
       "3  Brooke Greenstreet \"Babylove\"  [3, 4]   \n",
       "4                     C. Galindo  [1, 1]   \n",
       "\n",
       "                                             summary  \n",
       "0                                        Really cute  \n",
       "1                                2-year-old loves it  \n",
       "2                                           Fun game  \n",
       "3                               We love our Monkeys!  \n",
       "4  This is my granddaughters favorite app on my K...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzr_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9e881-d082-45b0-9ec4-3aaa717652ec",
   "metadata": {},
   "source": [
    "### Clean-up data:\n",
    "#### (1) remove empty review texts\n",
    "#### (2) remove dupplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8a51ece0-005d-4c6c-99f2-b3fc3ee0ba96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1N4O8VOJZTDVB</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1383350400</td>\n",
       "      <td>Loves the song, so he really couldn't wait to ...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>11 2, 2013</td>\n",
       "      <td>Annette Yancey</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Really cute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2HQWU6HUKIEC7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1323043200</td>\n",
       "      <td>Oh, how my little grandson loves this app. He'...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>12 5, 2011</td>\n",
       "      <td>Audiobook lover \"Kathy\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2-year-old loves it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1SXASF6GYG96I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1337558400</td>\n",
       "      <td>I found this at a perfect time since my daught...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>05 21, 2012</td>\n",
       "      <td>Barbara Gibbs</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Fun game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2B54P9ZDYH167</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1354752000</td>\n",
       "      <td>My 1 year old goes back to this game over and ...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>12 6, 2012</td>\n",
       "      <td>Brooke Greenstreet \"Babylove\"</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>We love our Monkeys!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFOFZDTX5UC6D</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1391212800</td>\n",
       "      <td>There are three different versions of the song...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>02 1, 2014</td>\n",
       "      <td>C. Galindo</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is my granddaughters favorite app on my K...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID  overall  unixReviewTime  \\\n",
       "0  A1N4O8VOJZTDVB      3.0      1383350400   \n",
       "1  A2HQWU6HUKIEC7      5.0      1323043200   \n",
       "2  A1SXASF6GYG96I      5.0      1337558400   \n",
       "3  A2B54P9ZDYH167      5.0      1354752000   \n",
       "4   AFOFZDTX5UC6D      5.0      1391212800   \n",
       "\n",
       "                                          reviewText        asin   reviewTime  \\\n",
       "0  Loves the song, so he really couldn't wait to ...  B004A9SDD8   11 2, 2013   \n",
       "1  Oh, how my little grandson loves this app. He'...  B004A9SDD8   12 5, 2011   \n",
       "2  I found this at a perfect time since my daught...  B004A9SDD8  05 21, 2012   \n",
       "3  My 1 year old goes back to this game over and ...  B004A9SDD8   12 6, 2012   \n",
       "4  There are three different versions of the song...  B004A9SDD8   02 1, 2014   \n",
       "\n",
       "                    reviewerName helpful  \\\n",
       "0                 Annette Yancey  [1, 1]   \n",
       "1        Audiobook lover \"Kathy\"  [0, 0]   \n",
       "2                  Barbara Gibbs  [0, 0]   \n",
       "3  Brooke Greenstreet \"Babylove\"  [3, 4]   \n",
       "4                     C. Galindo  [1, 1]   \n",
       "\n",
       "                                             summary  \n",
       "0                                        Really cute  \n",
       "1                                2-year-old loves it  \n",
       "2                                           Fun game  \n",
       "3                               We love our Monkeys!  \n",
       "4  This is my granddaughters favorite app on my K...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzr_clean = amzr_df[~amzr_df['reviewText'].isnull()]\n",
    "amzr_clean.drop_duplicates(subset=['reviewerID', 'asin', 'unixReviewTime'],inplace=True)\n",
    "amzr_clean.reset_index()\n",
    "amzr_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94367441-480f-4363-ae93-f1c5b2cc1efd",
   "metadata": {},
   "source": [
    "### Retreive helpfullness and bin into categories:\n",
    "- categories are from 1 to 5, i.e, from least helpfull to most helpfull\n",
    "- \"None\" catogory indicates no helpfulness rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c1858c9a-bb69-44af-a22a-d75c1a9af3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzr_clean['helpful_num'] = amzr_clean['helpful'].apply(lambda x: x[0])\n",
    "amzr_clean['helpful_den'] = amzr_clean['helpful'].apply(lambda x: x[1])\n",
    "amzr_clean['helpful_pct'] = np.where(amzr_clean['helpful_den'] > 0,\n",
    "                                  amzr_clean['helpful_num'] / amzr_clean['helpful_den'], -1)\n",
    "amzr_clean['helpfulness'] = pd.cut(x=amzr_clean['helpful_pct'], bins=[-1, 0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "                                         labels=['None', '1', '2', '3', '4', '5'], include_lowest=True)\n",
    "amzr_clean['sentiment'] = pd.cut(x=amzr_clean['overall'], bins=[-1, 1.5, 3.5, 6],\n",
    "                                         labels=[1,2,3], include_lowest=True)\n",
    "amzr_clean = amzr_clean.drop(columns=['helpful_num','helpful_den','helpful_pct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2fac84a5-3945-42af-9a41-c4df559e4590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>summary</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1N4O8VOJZTDVB</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1383350400</td>\n",
       "      <td>Loves the song, so he really couldn't wait to ...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>11 2, 2013</td>\n",
       "      <td>Annette Yancey</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Really cute</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2HQWU6HUKIEC7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1323043200</td>\n",
       "      <td>Oh, how my little grandson loves this app. He'...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>12 5, 2011</td>\n",
       "      <td>Audiobook lover \"Kathy\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2-year-old loves it</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1SXASF6GYG96I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1337558400</td>\n",
       "      <td>I found this at a perfect time since my daught...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>05 21, 2012</td>\n",
       "      <td>Barbara Gibbs</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Fun game</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2B54P9ZDYH167</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1354752000</td>\n",
       "      <td>My 1 year old goes back to this game over and ...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>12 6, 2012</td>\n",
       "      <td>Brooke Greenstreet \"Babylove\"</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>We love our Monkeys!</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFOFZDTX5UC6D</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1391212800</td>\n",
       "      <td>There are three different versions of the song...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>02 1, 2014</td>\n",
       "      <td>C. Galindo</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is my granddaughters favorite app on my K...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID  overall  unixReviewTime  \\\n",
       "0  A1N4O8VOJZTDVB      3.0      1383350400   \n",
       "1  A2HQWU6HUKIEC7      5.0      1323043200   \n",
       "2  A1SXASF6GYG96I      5.0      1337558400   \n",
       "3  A2B54P9ZDYH167      5.0      1354752000   \n",
       "4   AFOFZDTX5UC6D      5.0      1391212800   \n",
       "\n",
       "                                          reviewText        asin   reviewTime  \\\n",
       "0  Loves the song, so he really couldn't wait to ...  B004A9SDD8   11 2, 2013   \n",
       "1  Oh, how my little grandson loves this app. He'...  B004A9SDD8   12 5, 2011   \n",
       "2  I found this at a perfect time since my daught...  B004A9SDD8  05 21, 2012   \n",
       "3  My 1 year old goes back to this game over and ...  B004A9SDD8   12 6, 2012   \n",
       "4  There are three different versions of the song...  B004A9SDD8   02 1, 2014   \n",
       "\n",
       "                    reviewerName helpful  \\\n",
       "0                 Annette Yancey  [1, 1]   \n",
       "1        Audiobook lover \"Kathy\"  [0, 0]   \n",
       "2                  Barbara Gibbs  [0, 0]   \n",
       "3  Brooke Greenstreet \"Babylove\"  [3, 4]   \n",
       "4                     C. Galindo  [1, 1]   \n",
       "\n",
       "                                             summary helpfulness sentiment  \n",
       "0                                        Really cute           5         2  \n",
       "1                                2-year-old loves it        None         3  \n",
       "2                                           Fun game        None         3  \n",
       "3                               We love our Monkeys!           4         3  \n",
       "4  This is my granddaughters favorite app on my K...           5         3  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzr_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04d36f7-e3f7-45b5-b3a2-51e805f25d29",
   "metadata": {},
   "source": [
    "### Text processing\n",
    "- remove contractions\n",
    "- make lower-case\n",
    "- remove punctuations\n",
    "- remove stop words\n",
    "- lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1235571a-d52e-4492-81b4-44f14ed34b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(df_in, cols):\n",
    "    df =  df_in.copy()\n",
    "    # Columns to drop (intermediate processed strings) \n",
    "    cols_ext_todrop = ['nocontract','nocontract_str','tokenized','lower','no_punc','stopwords_removed','pos_tags','wordnet_pos']\n",
    "    stop_words = set(stopwords.words('english')) - {'not','no','nor',\"aren't\",\"isn't\"}\n",
    "    # Remove contractions\n",
    "    for c in cols:\n",
    "        df['nocontract'] = df[c].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "        df['nocontract_str'] = [' '.join(map(str, l)) for l in df['nocontract']]\n",
    "        # Tokenize\n",
    "        df['tokenized'] = df['nocontract_str'].apply(word_tokenize)\n",
    "        # make lower-case\n",
    "        df['lower'] = df['tokenized'].apply(lambda x: [word.lower() for word in x])\n",
    "        # remove punctuation\n",
    "        punc = string.punctuation\n",
    "        df['no_punc'] = df['lower'].apply(lambda x: [word for word in x if word not in punc])\n",
    "        # remove stop-words\n",
    "        df['stopwords_removed'] = df['no_punc'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "        # tag words\n",
    "        df['pos_tags'] = df['stopwords_removed'].apply(nltk.tag.pos_tag)\n",
    "        # lemmatize\n",
    "        def get_wordnet_pos(tag):\n",
    "            if tag.startswith('J'):\n",
    "                return wordnet.ADJ\n",
    "            elif tag.startswith('V'):\n",
    "                return wordnet.VERB\n",
    "            elif tag.startswith('N'):\n",
    "                return wordnet.NOUN\n",
    "            elif tag.startswith('R'):\n",
    "                return wordnet.ADV\n",
    "            else:\n",
    "                return wordnet.NOUN\n",
    "        df['wordnet_pos'] = df['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "        wnl = WordNetLemmatizer()\n",
    "        df[c+'_processed'] = df['wordnet_pos'].apply(lambda x: \" \".join([wnl.lemmatize(word, tag) for word, tag in x]))\n",
    "        # drop intermediate columns\n",
    "        df=df.drop(columns=cols_ext_todrop)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8f9b5-d563-49db-b28c-50d7fd516976",
   "metadata": {},
   "source": [
    "### Sample 20% of the data randomly and preprocess reviews and their summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "814a54b9-8e4f-4a68-8e29-c4be597a53a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208.74141097068787\n"
     ]
    }
   ],
   "source": [
    "amzr_clean_sample = amzr_clean.sample(frac=0.2, replace=False, random_state=1)\n",
    "start = time.time()\n",
    "amzr_clean_sample = process_text(amzr_clean_sample, ['reviewText','summary'])\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d5df07d1-167f-4e42-b83b-4874376eac12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>summary</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reviewText_processed</th>\n",
       "      <th>summary_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471454</th>\n",
       "      <td>A1O4ZL0WU2GAGV</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1369526400</td>\n",
       "      <td>I love this game. It's colorful, imaginative, ...</td>\n",
       "      <td>B00AEJPK0C</td>\n",
       "      <td>05 26, 2013</td>\n",
       "      <td>Merri Lockerby</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Very addicting</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>love game colorful imaginative great replay va...</td>\n",
       "      <td>addict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139042</th>\n",
       "      <td>AXW0GZEQUPBN2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1358035200</td>\n",
       "      <td>I'm particularly happy to be able to replay ga...</td>\n",
       "      <td>B0063IH60K</td>\n",
       "      <td>01 13, 2013</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Very good game</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>particularly happy able replay game find corre...</td>\n",
       "      <td>good game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204419</th>\n",
       "      <td>A1Q91YOUFTME7K</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1364169600</td>\n",
       "      <td>Bought this for my 5 year old son, and he did ...</td>\n",
       "      <td>B006VJQ14I</td>\n",
       "      <td>03 25, 2013</td>\n",
       "      <td>Cassandra Edwards</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>Not great for kids</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>bought 5 year old son not enjoy way difficult ...</td>\n",
       "      <td>not great kid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679356</th>\n",
       "      <td>A2I1J6RNUV5RQZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1391644800</td>\n",
       "      <td>My one and a half year old mastered this in li...</td>\n",
       "      <td>B00FL4EUZG</td>\n",
       "      <td>02 6, 2014</td>\n",
       "      <td>Heather M Pederson</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>OMG!  So fun!</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>one half year old master like 15 minute impres...</td>\n",
       "      <td>omg fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105679</th>\n",
       "      <td>A31UAATZBRM9GG</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1402012800</td>\n",
       "      <td>I LOVE the game!!! I love the sounds the fruit...</td>\n",
       "      <td>B005HSL626</td>\n",
       "      <td>06 6, 2014</td>\n",
       "      <td>vbp36</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>BEST GAME EVER</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>love game love sound fruit make slice love cho...</td>\n",
       "      <td>best game ever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID  overall  unixReviewTime  \\\n",
       "471454  A1O4ZL0WU2GAGV      5.0      1369526400   \n",
       "139042   AXW0GZEQUPBN2      4.0      1358035200   \n",
       "204419  A1Q91YOUFTME7K      2.0      1364169600   \n",
       "679356  A2I1J6RNUV5RQZ      5.0      1391644800   \n",
       "105679  A31UAATZBRM9GG      5.0      1402012800   \n",
       "\n",
       "                                               reviewText        asin  \\\n",
       "471454  I love this game. It's colorful, imaginative, ...  B00AEJPK0C   \n",
       "139042  I'm particularly happy to be able to replay ga...  B0063IH60K   \n",
       "204419  Bought this for my 5 year old son, and he did ...  B006VJQ14I   \n",
       "679356  My one and a half year old mastered this in li...  B00FL4EUZG   \n",
       "105679  I LOVE the game!!! I love the sounds the fruit...  B005HSL626   \n",
       "\n",
       "         reviewTime        reviewerName helpful             summary  \\\n",
       "471454  05 26, 2013      Merri Lockerby  [1, 1]      Very addicting   \n",
       "139042  01 13, 2013                None  [0, 0]      Very good game   \n",
       "204419  03 25, 2013   Cassandra Edwards  [0, 1]  Not great for kids   \n",
       "679356   02 6, 2014  Heather M Pederson  [1, 1]       OMG!  So fun!   \n",
       "105679   06 6, 2014               vbp36  [2, 2]      BEST GAME EVER   \n",
       "\n",
       "       helpfulness sentiment  \\\n",
       "471454           5         3   \n",
       "139042        None         3   \n",
       "204419        None         2   \n",
       "679356           5         3   \n",
       "105679           5         3   \n",
       "\n",
       "                                     reviewText_processed summary_processed  \n",
       "471454  love game colorful imaginative great replay va...            addict  \n",
       "139042  particularly happy able replay game find corre...         good game  \n",
       "204419  bought 5 year old son not enjoy way difficult ...     not great kid  \n",
       "679356  one half year old master like 15 minute impres...           omg fun  \n",
       "105679  love game love sound fruit make slice love cho...    best game ever  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzr_clean_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231772c7-0324-4261-8664-7a7405ebea1a",
   "metadata": {},
   "source": [
    "### Split data into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2d47cebb-cefe-4195-8a02-c492c6165789",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = amzr_clean_sample['reviewText'].values.tolist()\n",
    "labels = amzr_clean_sample['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "170e3bb3-7d3a-4ae3-9e17-00ff8a26a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_sentences, validation_sentences, training_labels, validation_labels = train_test_split(reviews, labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5add910f-9a38-4bff-acde-bef3e36ace50",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_575456/1678195014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTFDistilBertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Assign tokenizer object to the tokenizer class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBertTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distilbert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/NLP_reviews/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1688\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m                     resolved_vocab_files[file_id] = cached_path(\n\u001b[0m\u001b[1;32m   1691\u001b[0m                         \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m                         \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_reviews/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1402\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1404\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m   1405\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_reviews/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1665\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{url} not found in cache or force_download set to True, downloading to {temp_file.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m             \u001b[0mhttp_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"storing {url} in cache at {cache_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_reviews/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[0mcontent_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresume_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontent_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m     progress = tqdm(\n\u001b[0m\u001b[1;32m   1519\u001b[0m         \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m         \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_reviews/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_printer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplayed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_reviews/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# Prepare IPython progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# #187 #451 #558 #872\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "#Assign tokenizer object to the tokenizer class\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f433f-440b-4cc5-be17-ce0c3500552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(training_sentences,\n",
    "                            truncation=True,\n",
    "                            padding=True)\n",
    "val_encodings = tokenizer(validation_sentences,\n",
    "                            truncation=True,\n",
    "                            padding=True)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "                            dict(train_encodings),\n",
    "                            training_labels\n",
    "                            ))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "                            dict(val_encodings),\n",
    "                            validation_labels\n",
    "                            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39608c8e-f280-4add-b312-f20371064ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c289d94-dd78-4971-a421-a9eb1fd9f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5, epsilon=1e-08)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])\n",
    "model.fit(train_dataset.shuffle(100).batch(16),\n",
    "          epochs=2,\n",
    "          batch_size=16,\n",
    "          validation_data=val_dataset.shuffle(100).batch(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de43afd4-fb10-49c3-9970-d80e7fc81a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./sentiment\")\n",
    "loaded_model = TFDistilBertForSequenceClassification.from_pretrained(\"./sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21573a43-0494-4f3c-afa5-f0a7899ee900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5934b0ea-ae7c-48c2-852a-c5674ea27927",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = amzr_clean.head(10000).copy()\n",
    "cols = ['reviewText','summary']\n",
    "cols_ext_todrop = ['nocontract','nocontract_str','tokenized','lower','no_punc','stopwords_removed','pos_tags','wordnet_pos']\n",
    "# Remove contractions\n",
    "for c in cols:\n",
    "    df['nocontract'] = df[c].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "    df['nocontract_str'] = [' '.join(map(str, l)) for l in df['nocontract']]\n",
    "    # Tokenize\n",
    "    df['tokenized'] = df['nocontract_str'].apply(word_tokenize)\n",
    "    # make lower-case\n",
    "    df['lower'] = df['tokenized'].apply(lambda x: [word.lower() for word in x])\n",
    "    # remove punctuation\n",
    "    punc = string.punctuation\n",
    "    df['no_punc'] = df['lower'].apply(lambda x: [word for word in x if word not in punc])\n",
    "    # remove stop-words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df['stopwords_removed'] = df['no_punc'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    # tag words\n",
    "    df['pos_tags'] = df['stopwords_removed'].apply(nltk.tag.pos_tag)\n",
    "    # lemmatize\n",
    "    def get_wordnet_pos(tag):\n",
    "        if tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "    df['wordnet_pos'] = df['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "    wnl = WordNetLemmatizer()\n",
    "    df[c+'_processed'] = df['wordnet_pos'].apply(lambda x: \" \".join([wnl.lemmatize(word, tag) for word, tag in x]))\n",
    "    # drop intermediate columns\n",
    "    df=df.drop(columns=cols_ext_todrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a50dfce4-8026-42c3-82ab-2774299f0b94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>summary</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>reviewText_processed</th>\n",
       "      <th>summary_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1N4O8VOJZTDVB</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1383350400</td>\n",
       "      <td>Loves the song, so he really couldn't wait to ...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>11 2, 2013</td>\n",
       "      <td>Annette Yancey</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Really cute</td>\n",
       "      <td>5</td>\n",
       "      <td>Loves song really could wait play A little les...</td>\n",
       "      <td>Really cute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2HQWU6HUKIEC7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1323043200</td>\n",
       "      <td>Oh, how my little grandson loves this app. He'...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>12 5, 2011</td>\n",
       "      <td>Audiobook lover \"Kathy\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2-year-old loves it</td>\n",
       "      <td>None</td>\n",
       "      <td>Oh little grandson love app always ask `` Monk...</td>\n",
       "      <td>2-year-old love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1SXASF6GYG96I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1337558400</td>\n",
       "      <td>I found this at a perfect time since my daught...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>05 21, 2012</td>\n",
       "      <td>Barbara Gibbs</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Fun game</td>\n",
       "      <td>None</td>\n",
       "      <td>I find perfect time since daughter 's favorite...</td>\n",
       "      <td>Fun game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2B54P9ZDYH167</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1354752000</td>\n",
       "      <td>My 1 year old goes back to this game over and ...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>12 6, 2012</td>\n",
       "      <td>Brooke Greenstreet \"Babylove\"</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>We love our Monkeys!</td>\n",
       "      <td>4</td>\n",
       "      <td>My 1 year old go back game It simple easy todd...</td>\n",
       "      <td>We love Monkeys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFOFZDTX5UC6D</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1391212800</td>\n",
       "      <td>There are three different versions of the song...</td>\n",
       "      <td>B004A9SDD8</td>\n",
       "      <td>02 1, 2014</td>\n",
       "      <td>C. Galindo</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is my granddaughters favorite app on my K...</td>\n",
       "      <td>5</td>\n",
       "      <td>There three different version song The game ke...</td>\n",
       "      <td>This granddaughters favorite app Kindle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>AQWEAK4VJU5ZR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1344124800</td>\n",
       "      <td>This is a great app for logging your food inta...</td>\n",
       "      <td>B004H6WTJI</td>\n",
       "      <td>08 5, 2012</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Great App!!</td>\n",
       "      <td>None</td>\n",
       "      <td>This great app log food intake exercise It hel...</td>\n",
       "      <td>Great App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>A3V3UMS79UTFFG</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1344556800</td>\n",
       "      <td>This is a great app for tracking food. That's ...</td>\n",
       "      <td>B004H6WTJI</td>\n",
       "      <td>08 10, 2012</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Food tracking solves migrain trigger</td>\n",
       "      <td>None</td>\n",
       "      <td>This great app track food something doctor try...</td>\n",
       "      <td>Food track solves migrain trigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>A13SC4R3K4C8P2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1329955200</td>\n",
       "      <td>This is a great app. I downloaded it in Januar...</td>\n",
       "      <td>B004H6WTJI</td>\n",
       "      <td>02 23, 2012</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Best APP Really helps with calorie awareness</td>\n",
       "      <td>None</td>\n",
       "      <td>This great app I download January I become awa...</td>\n",
       "      <td>Best APP Really help calorie awareness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>AQ2Q9S0Y9YAHA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1342656000</td>\n",
       "      <td>This is a great app!  I highly recommend this....</td>\n",
       "      <td>B004H6WTJI</td>\n",
       "      <td>07 19, 2012</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Great!</td>\n",
       "      <td>None</td>\n",
       "      <td>This great app I highly recommend If honest pu...</td>\n",
       "      <td>Great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>A1EA0SCL3NTEKA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1345939200</td>\n",
       "      <td>This is a great app. I'm doing the leangains d...</td>\n",
       "      <td>B004H6WTJI</td>\n",
       "      <td>08 26, 2012</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Great App</td>\n",
       "      <td>None</td>\n",
       "      <td>This great app I leangains diet app make calor...</td>\n",
       "      <td>Great App</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          reviewerID  overall  unixReviewTime  \\\n",
       "0     A1N4O8VOJZTDVB      3.0      1383350400   \n",
       "1     A2HQWU6HUKIEC7      5.0      1323043200   \n",
       "2     A1SXASF6GYG96I      5.0      1337558400   \n",
       "3     A2B54P9ZDYH167      5.0      1354752000   \n",
       "4      AFOFZDTX5UC6D      5.0      1391212800   \n",
       "...              ...      ...             ...   \n",
       "9995   AQWEAK4VJU5ZR      5.0      1344124800   \n",
       "9996  A3V3UMS79UTFFG      4.0      1344556800   \n",
       "9997  A13SC4R3K4C8P2      5.0      1329955200   \n",
       "9998   AQ2Q9S0Y9YAHA      5.0      1342656000   \n",
       "9999  A1EA0SCL3NTEKA      5.0      1345939200   \n",
       "\n",
       "                                             reviewText        asin  \\\n",
       "0     Loves the song, so he really couldn't wait to ...  B004A9SDD8   \n",
       "1     Oh, how my little grandson loves this app. He'...  B004A9SDD8   \n",
       "2     I found this at a perfect time since my daught...  B004A9SDD8   \n",
       "3     My 1 year old goes back to this game over and ...  B004A9SDD8   \n",
       "4     There are three different versions of the song...  B004A9SDD8   \n",
       "...                                                 ...         ...   \n",
       "9995  This is a great app for logging your food inta...  B004H6WTJI   \n",
       "9996  This is a great app for tracking food. That's ...  B004H6WTJI   \n",
       "9997  This is a great app. I downloaded it in Januar...  B004H6WTJI   \n",
       "9998  This is a great app!  I highly recommend this....  B004H6WTJI   \n",
       "9999  This is a great app. I'm doing the leangains d...  B004H6WTJI   \n",
       "\n",
       "       reviewTime                   reviewerName helpful  \\\n",
       "0      11 2, 2013                 Annette Yancey  [1, 1]   \n",
       "1      12 5, 2011        Audiobook lover \"Kathy\"  [0, 0]   \n",
       "2     05 21, 2012                  Barbara Gibbs  [0, 0]   \n",
       "3      12 6, 2012  Brooke Greenstreet \"Babylove\"  [3, 4]   \n",
       "4      02 1, 2014                     C. Galindo  [1, 1]   \n",
       "...           ...                            ...     ...   \n",
       "9995   08 5, 2012                           None  [0, 0]   \n",
       "9996  08 10, 2012                           None  [0, 0]   \n",
       "9997  02 23, 2012                           None  [0, 0]   \n",
       "9998  07 19, 2012                           None  [0, 0]   \n",
       "9999  08 26, 2012                           None  [0, 0]   \n",
       "\n",
       "                                                summary helpfulness  \\\n",
       "0                                           Really cute           5   \n",
       "1                                   2-year-old loves it        None   \n",
       "2                                              Fun game        None   \n",
       "3                                  We love our Monkeys!           4   \n",
       "4     This is my granddaughters favorite app on my K...           5   \n",
       "...                                                 ...         ...   \n",
       "9995                                        Great App!!        None   \n",
       "9996               Food tracking solves migrain trigger        None   \n",
       "9997       Best APP Really helps with calorie awareness        None   \n",
       "9998                                             Great!        None   \n",
       "9999                                          Great App        None   \n",
       "\n",
       "                                   reviewText_processed  \\\n",
       "0     Loves song really could wait play A little les...   \n",
       "1     Oh little grandson love app always ask `` Monk...   \n",
       "2     I find perfect time since daughter 's favorite...   \n",
       "3     My 1 year old go back game It simple easy todd...   \n",
       "4     There three different version song The game ke...   \n",
       "...                                                 ...   \n",
       "9995  This great app log food intake exercise It hel...   \n",
       "9996  This great app track food something doctor try...   \n",
       "9997  This great app I download January I become awa...   \n",
       "9998  This great app I highly recommend If honest pu...   \n",
       "9999  This great app I leangains diet app make calor...   \n",
       "\n",
       "                            summary_processed  \n",
       "0                                 Really cute  \n",
       "1                             2-year-old love  \n",
       "2                                    Fun game  \n",
       "3                             We love Monkeys  \n",
       "4     This granddaughters favorite app Kindle  \n",
       "...                                       ...  \n",
       "9995                                Great App  \n",
       "9996        Food track solves migrain trigger  \n",
       "9997   Best APP Really help calorie awareness  \n",
       "9998                                    Great  \n",
       "9999                                Great App  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2103fc2f-b8df-402d-92fd-ebabae6b0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzr_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cdee76e7-2220-40fa-ae6e-18f9d4a4dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### checka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ace29112-ee0b-49ad-a981-8fd9faec330c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87271"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(amzr_df['reviewerID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b08d87e6-fc7e-414a-b1f7-47257fcff7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13209"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(amzr_df['asin']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6050122-b46e-4f4c-8728-e92e297614c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
